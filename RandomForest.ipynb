{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d125ca4-5cb4-4569-b6d3-ab2f1c3b43b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RandomForest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65d0fce5-620f-42ab-b347-309b7f2286c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "Starting installation...\n",
      "Please <<RESTART YOUR KERNEL>> (Kernel->Restart Kernel and Clear All Outputs)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export version=`python --version |awk '{print $2}' |awk -F\".\" '{print $1$2}'`\n",
    "\n",
    "echo $version\n",
    "\n",
    "if [ $version == '36' ] || [ $version == '37' ]; then\n",
    "    echo 'Starting installation...'\n",
    "    pip3 install pyspark==2.4.8 wget==3.2 pyspark2pmml==0.5.1 > install.log 2> install.log\n",
    "    if [ $? == 0 ]; then\n",
    "        echo 'Please <<RESTART YOUR KERNEL>> (Kernel->Restart Kernel and Clear All Outputs)'\n",
    "    else\n",
    "        echo 'Installation failed, please check log:'\n",
    "        cat install.log\n",
    "    fi\n",
    "elif [ $version == '38' ] || [ $version == '39' ]; then\n",
    "    pip3 install pyspark==3.1.2 wget==3.2 pyspark2pmml==0.5.1 > install.log 2> install.log\n",
    "    if [ $? == 0 ]; then\n",
    "        echo 'Please <<RESTART YOUR KERNEL>> (Kernel->Restart Kernel and Clear All Outputs)'\n",
    "    else\n",
    "        echo 'Installation failed, please check log:'\n",
    "        cat install.log\n",
    "    fi\n",
    "else\n",
    "    echo 'Currently only python 3.6, 3.7 , 3.8 and 3.9 are supported, in case you need a different version please open an issue at https://github.com/IBM/claimed/issues'\n",
    "    exit -1\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e3fb3e7-79bd-4fb3-a7ec-4484f0519280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import pandas as pd\n",
    "import fnmatch\n",
    "import re\n",
    "import sys\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import logging\n",
    "import site\n",
    "import wget\n",
    "from pyspark.ml import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cc29934-5d62-4da8-b5d9-32c110365311",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if sys.version[0:3] == '3.9':\n",
    "    url = ('https://github.com/jpmml/jpmml-sparkml/releases/download/1.7.2/'\n",
    "           'jpmml-sparkml-executable-1.7.2.jar')\n",
    "    wget.download(url)\n",
    "    shutil.copy('jpmml-sparkml-executable-1.7.2.jar',\n",
    "                site.getsitepackages()[0] + '/pyspark/jars/')\n",
    "elif sys.version[0:3] == '3.8':\n",
    "    url = ('https://github.com/jpmml/jpmml-sparkml/releases/download/1.7.2/'\n",
    "           'jpmml-sparkml-executable-1.7.2.jar')\n",
    "    wget.download(url)\n",
    "    shutil.copy('jpmml-sparkml-executable-1.7.2.jar',\n",
    "                site.getsitepackages()[0] + '/pyspark/jars/')\n",
    "elif sys.version[0:3] == '3.7':\n",
    "    url = ('https://github.com/jpmml/jpmml-sparkml/releases/download/1.5.12/'\n",
    "           'jpmml-sparkml-executable-1.5.12.jar')\n",
    "    wget.download(url)\n",
    "elif sys.version[0:3] == '3.6':\n",
    "    url = ('https://github.com/jpmml/jpmml-sparkml/releases/download/1.5.12/'\n",
    "           'jpmml-sparkml-executable-1.5.12.jar')\n",
    "    wget.download(url)\n",
    "else:\n",
    "    raise Exception('Currently only python 3.6 , 3.7, 3,8 and 3.9 is supported, in case '\n",
    "                    'you need a different version please open an issue at '\n",
    "                    'https://github.com/IBM/claimed/issues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94d45daa-de8f-4da2-847a-e117fdfec566",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/01 00:36:19 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "sc= SparkContext()\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"Random Forest Classification\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a3086eb-1d98-40d8-9acf-f4eb7ed3e8e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_csv = os.environ.get('data_csv', 'data.csv')\n",
    "data_parquet = os.environ.get('data_parquet', 'data.parquet')\n",
    "master = os.environ.get('master', \"local[*]\")\n",
    "data_dir = os.environ.get('data_dir', '../../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5dcac9e-0578-4f3a-aff3-a10e429df27e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_parquet = 'data.parquet'\n",
    "data_csv = 'rf.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "370d1d06-8b81-4eeb-b37b-f2790c56d7e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skip = False\n",
    "if os.path.exists(data_dir + data_csv):\n",
    "    skip = True\n",
    "if not skip:\n",
    "    df = spark.read.parquet(data_dir + data_parquet)\n",
    "if not skip:\n",
    "    if os.path.exists(data_dir + data_csv):\n",
    "        shutil.rmtree(data_dir + data_csv)\n",
    "    df.coalesce(1).write.option(\"header\", \"true\").csv(data_dir + data_csv)\n",
    "    file = glob.glob(data_dir + data_csv + '/part-*')\n",
    "    shutil.move(file[0], data_dir + data_csv + '.tmp')\n",
    "    shutil.rmtree(data_dir + data_csv)\n",
    "    shutil.move(data_dir + data_csv + '.tmp', data_dir + data_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "148a09bc-f4a0-4c24-aeb5-f461cb2e1485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd_read = pd.read_csv('rf.csv')\n",
    "\n",
    "sdf = spark.createDataFrame(pd_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef894c67-22d0-42b2-be43-30f1bc85366c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sdf = sdf.withColumn(\"x\", sdf.x.cast(DoubleType()))\n",
    "sdf = sdf.withColumn(\"y\", sdf.y.cast(DoubleType()))\n",
    "sdf = sdf.withColumn(\"z\", sdf.z.cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45c1888c-ad0e-4b4c-8812-d898d1811110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "splits = sdf.randomSplit([0.8, 0.2], seed=1)\n",
    "df_train = splits[0]\n",
    "df_test = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0aa6428b-46a7-411c-b6c8-90f2c1a76447",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"class\", outputCol=\"label\")\n",
    "\n",
    "input_columns = ['x', 'y', 'z']\n",
    "\n",
    "vectorAssembler = VectorAssembler(inputCols=input_columns,\n",
    "                                  outputCol=\"features\")\n",
    "\n",
    "normalizer = MinMaxScaler(inputCol=\"features\", outputCol=\"features_norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b8bd642-eeb4-4a50-b395-d75e83572efa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_trees = [10, 20]\n",
    "max_depth = [5, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb25efc-ecf8-44ae-bef0-1029d88c7fb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/01 00:37:12 WARN scheduler.TaskSetManager: Stage 0 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:37:25 WARN scheduler.TaskSetManager: Stage 2 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:37:35 WARN scheduler.TaskSetManager: Stage 4 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:37:36 WARN scheduler.TaskSetManager: Stage 5 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:37:41 WARN scheduler.TaskSetManager: Stage 6 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:37:47 WARN scheduler.TaskSetManager: Stage 8 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:37:54 WARN scheduler.TaskSetManager: Stage 10 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:37:56 WARN scheduler.TaskSetManager: Stage 12 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:37:57 WARN scheduler.TaskSetManager: Stage 14 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:37:58 WARN scheduler.TaskSetManager: Stage 16 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:38:00 WARN scheduler.TaskSetManager: Stage 18 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:38:01 WARN scheduler.TaskSetManager: Stage 19 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:38:06 WARN scheduler.TaskSetManager: Stage 21 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numTrees = [10, 20], maxDepth = [5, 7] => Accuracy = 0.44843979503739334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/01 00:38:09 WARN scheduler.TaskSetManager: Stage 23 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:38:12 WARN scheduler.TaskSetManager: Stage 25 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:38:15 WARN scheduler.TaskSetManager: Stage 27 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:38:15 WARN scheduler.TaskSetManager: Stage 28 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:38:17 WARN scheduler.TaskSetManager: Stage 29 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:38:20 WARN scheduler.TaskSetManager: Stage 31 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:38:25 WARN scheduler.TaskSetManager: Stage 33 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:38:25 WARN scheduler.TaskSetManager: Stage 35 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:38:26 WARN scheduler.TaskSetManager: Stage 37 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:38:28 WARN scheduler.TaskSetManager: Stage 39 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:38:29 WARN scheduler.TaskSetManager: Stage 41 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:38:30 WARN scheduler.TaskSetManager: Stage 43 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:38:32 WARN scheduler.TaskSetManager: Stage 45 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:38:33 WARN scheduler.TaskSetManager: Stage 46 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:38:36 WARN scheduler.TaskSetManager: Stage 48 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numTrees = [10, 20], maxDepth = [5, 7] => Accuracy = 0.46441745994371375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/01 00:38:39 WARN scheduler.TaskSetManager: Stage 50 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:38:42 WARN scheduler.TaskSetManager: Stage 52 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:38:45 WARN scheduler.TaskSetManager: Stage 54 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "23/11/01 00:38:45 WARN scheduler.TaskSetManager: Stage 55 contains a task of very large size (908 KB). The maximum recommended task size is 100 KB.\n",
      "[Stage 55:>                                                         (0 + 8) / 8]"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0\n",
    "best_hyperparameters = {}\n",
    "\n",
    "# Loop through hyperparameters\n",
    "for trees in num_trees:\n",
    "    for depth in max_depth:\n",
    "        # Initialize Random Forest Classifier\n",
    "        rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=trees, maxDepth=depth, seed=1)\n",
    "        \n",
    "        pipeline = Pipeline(stages=[indexer, vectorAssembler, normalizer, rf])\n",
    "        # Train the models\n",
    "        model = pipeline.fit(df_train)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        predictions = model.transform(df_test)\n",
    "\n",
    "        # Define the evaluator\n",
    "        evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "        # Evaluate the model\n",
    "        accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "        # Print the hyperparameters and accuracy\n",
    "        print(f\"numTrees = {num_trees}, maxDepth = {max_depth} => Accuracy = {accuracy}\")\n",
    "\n",
    "        # Track the best hyperparameters\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_hyperparameters['numTrees'] = trees\n",
    "            best_hyperparameters['maxDepth'] = depth\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(f\"\\nBest Hyperparameters: {best_hyperparameters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14a2549-07a2-45e1-bf17-aa89c7c7b35e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0469279-9f72-4d8d-90b8-84964a868621",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
